# 📺 影像捕捉功能開發紀錄

## 🎯 功能概述
**功能名稱**: 影像捕捉與即時串流系統  
**開發時間**: 2024年10月  
**技術棧**: WebRTC P2P + WebSocket 降級 + Unity接收端  
**主要目標**: 實現低延遲、高品質的螢幕捕獲與即時傳輸到Unity  

## 🏗️ 系統架構設計

### 整體架構圖
```
手機瀏覽器 (發送端)
├── WebRTC P2P 優先路徑 (100-300ms延遲)
│   ├── getDisplayMedia() 螢幕捕獲
│   ├── RTCPeerConnection 點對點連接
│   └── 直接視頻軌道傳輸
└── WebSocket 降級路徑 (500-1000ms延遲)
    ├── Canvas 捕獲幀
    ├── JPEG 編碼 (70%品質)
    └── Base64 數據傳輸

Railway 伺服器 (信令中繼)
├── WebRTC 信令轉發 (offer/answer/candidate)
├── 房間配對管理
└── WebSocket 螢幕數據廣播

Unity 接收端
├── WebRTCScreenReceiver (P2P優先)
│   ├── 視頻軌道接收
│   ├── 紋理即時更新
│   └── MaterialPropertyBlock 優化
└── ScreenCaptureHandler (WebSocket降級)
    ├── 幀數據處理
    ├── Texture2D 重建
    └── 自適應幀率調整
```

### 技術決策記錄

#### 1. 雙路徑設計決策
**問題**: 如何確保影像傳輸的可靠性？  
**解決方案**: WebRTC P2P 優先 + WebSocket 降級  
**理由**: 
- WebRTC 提供最低延遲 (100-300ms)
- WebSocket 作為備用方案確保連接穩定性
- 自動降級機制提升用戶體驗

#### 2. 房間制度設計
**問題**: 如何管理多對端連接？  
**解決方案**: 房間配對系統  
**實現**: 
```javascript
// 房間配對邏輯
if (peers.size === 2) {
    // 通知所有同房 peer 準備就緒
    for (const peer of peers) {
        peer.send(JSON.stringify({
            type: 'ready',
            room: room,
            message: 'Both peers joined, WebRTC can start'
        }));
    }
}
```

#### 3. 性能優化策略
**問題**: 如何平衡品質與性能？  
**解決方案**: 多層優化策略
- **解析度**: 1280x720 (平衡品質與頻寬)
- **幀率**: 30fps (WebRTC) / 15fps (WebSocket)
- **編碼**: H.264 (WebRTC) / JPEG 70% (WebSocket)
- **記憶體**: Texture2D 重用 + 佇列限制

## 📱 前端實現詳情

### 1. WebRTC 螢幕捕獲類 (WebRTCScreenCapture)

#### 核心初始化流程
```javascript
class WebRTCScreenCapture {
    async start() {
        // 1. 獲取螢幕流
        this.localStream = await navigator.mediaDevices.getDisplayMedia({
            video: {
                width: { ideal: 1280 },
                height: { ideal: 720 },
                frameRate: { ideal: 30, max: 30 }
            },
            audio: false
        });
        
        // 2. 設置 contentHint
        const [videoTrack] = this.localStream.getVideoTracks();
        videoTrack.contentHint = 'text'; // 文字清晰優先
        
        // 3. 創建 RTCPeerConnection
        this.peerConnection = new RTCPeerConnection(this.rtcConfig);
        
        // 4. 添加軌道
        this.peerConnection.addTrack(videoTrack, this.localStream);
        
        // 5. 創建並發送 Offer
        const offer = await this.peerConnection.createOffer();
        await this.peerConnection.setLocalDescription(offer);
        this.signalingWS.send(JSON.stringify({
            type: 'offer',
            sdp: offer.sdp
        }));
    }
}
```

#### ICE 連接狀態監控
```javascript
this.peerConnection.oniceconnectionstatechange = () => {
    const state = this.peerConnection.iceConnectionState;
    console.log('🔌 ICE 狀態:', state);
    
    if (state === 'connected' || state === 'completed') {
        this.iceOk = true;
        this.updateUI('WebRTC P2P', 'connected');
    } else if (state === 'failed' || state === 'disconnected') {
        this.teardown(true); // 降級到 WebSocket
    }
};
```

#### 性能統計監控
```javascript
startStatsMonitoring() {
    this.statsTimer = setInterval(async () => {
        const stats = await this.peerConnection.getStats();
        let outbound, pair;
        
        stats.forEach(r => {
            if (r.type === 'candidate-pair' && r.state === 'succeeded') pair = r;
            if (r.type === 'outbound-rtp' && r.kind === 'video') outbound = r;
        });
        
        if (outbound) {
            const dt = (outbound.timestamp - last.ts) / 1000;
            const db = outbound.bytesSent - last.bytes;
            this.stats.bitrate = Math.round((db * 8) / 1000 / dt); // kbps
            this.stats.fps = Math.round((outbound.framesEncoded - last.frames) / dt);
        }
        
        if (pair) {
            this.stats.rtt = Math.round(pair.currentRoundTripTime * 1000);
        }
        
        this.updateStatsUI();
    }, 2000);
}
```

### 2. WebSocket 降級實現

#### Canvas 捕獲流程
```javascript
function captureScreenFrames() {
    if (!isScreenCapturing) return;
    
    const video = document.getElementById('screenCaptureVideo');
    
    // 繪製當前幀到Canvas
    screenCaptureCtx.drawImage(video, 0, 0, 
        screenCaptureCanvas.width, screenCaptureCanvas.height);
    
    // 轉換為JPEG並發送
    screenCaptureCanvas.toBlob((blob) => {
        if (blob && gyroWS.isConnected) {
            blob.arrayBuffer().then(buffer => {
                const imageData = new Uint8Array(buffer);
                gyroWS.sendScreenCaptureData(imageData, buffer.byteLength);
            });
        }
    }, 'image/jpeg', 0.7); // 70%品質
    
    // 15fps (每66ms一幀)
    setTimeout(() => captureScreenFrames(), 66);
}
```

#### 雙包傳輸機制
```javascript
sendScreenCaptureData(imageData, size) {
    // 雙包傳輸：先發送header
    const header = {
        type: 'screen_capture_header',
        clientId: this.clientId || 0,
        timestamp: Date.now(),
        size: size
    };
    this.ws.send(JSON.stringify(header));
    
    // 再發送二進位數據
    this.ws.send(imageData);
}
```

### 3. 智能降級機制

#### 超時與降級邏輯
```javascript
setupTimeout() {
    // T+10s：如果還沒連上，嘗試 restartIce
    this.t1 = setTimeout(async () => {
        if (!this.iceOk) {
            console.warn('⚠️ 10秒超時，嘗試 restartIce');
            try {
                await this.peerConnection.restartIce();
            } catch (e) {
                console.error('restartIce 失敗:', e);
            }
            
            // T+18s：仍不通 → 降級
            this.t2 = setTimeout(() => {
                if (!this.iceOk) {
                    console.warn('⚠️ 18秒仍未連接，降級到 WebSocket');
                    this.teardown(true);
                }
            }, 8000);
        }
    }, 10000);
}
```

## 🖥️ 伺服器端實現

### 1. WebSocket 伺服器配置

#### 房間管理系統
```javascript
// 房間管理
const rooms = new Map(); // roomId -> Set<WebSocket>

// 房間加入邏輯
if (msg.type === 'join') {
    const { room, role } = msg; // role: 'web-sender' / 'unity-receiver'
    ws.room = room;
    ws.role = role;
    
    // 檢查房間限制
    const peers = rooms.get(room) || new Set();
    const sameRole = Array.from(peers).find(p => p.role === role);
    if (sameRole) {
        // 踢掉舊的或拒絕新的
        sameRole.close(1000, 'Replaced by new peer');
    }
    
    peers.add(ws);
    rooms.set(room, peers);
    
    // 檢查房間是否已滿（2個 peer）
    if (peers.size === 2) {
        console.log(`🤝 Room ${room} has both peers ready, notifying all`);
        
        // 通知所有同房 peer 準備就緒
        for (const peer of peers) {
            if (peer.readyState === WebSocket.OPEN) {
                peer.send(JSON.stringify({
                    type: 'ready',
                    room: room,
                    message: 'Both peers joined, WebRTC can start'
                }));
            }
        }
    }
}
```

#### WebRTC 信令轉發
```javascript
// WebRTC 原生三型別轉發
if (['offer', 'answer', 'candidate'].includes(msg.type)) {
    if (!ws.room) {
        console.warn(`⚠️ WebSocket ${ws.id} 沒有房間信息，無法轉發信令`);
        return;
    }
    
    const peers = rooms.get(ws.room) || new Set();
    
    for (const peer of peers) {
        if (peer !== ws && peer.readyState === WebSocket.OPEN) {
            peer.send(JSON.stringify(msg));
            console.log(`📤 已轉發 ${msg.type} 給 ${peer.role}`);
        }
    }
    
    // 更新統計
    if (msg.type === 'offer') stats.webrtcOffers++;
    else if (msg.type === 'answer') stats.webrtcAnswers++;
    else if (msg.type === 'candidate') stats.webrtcCandidates++;
}
```

#### 螢幕捕獲數據處理
```javascript
// 二進位數據：僅用於螢幕捕獲幀
if (isBinary) {
    if (ws.screenCaptureHeader) {
        const header = ws.screenCaptureHeader;
        const bytes = Buffer.isBuffer(data) ? new Uint8Array(data) : new Uint8Array();
        const imageData = Array.from(bytes);
        
        stats.screenCaptureMessages++;
        
        const out = {
            type: 'screen_capture',
            clientId: header.clientId,
            timestamp: header.timestamp,
            size: header.size,
            image: imageData
        };
        
        // 廣播給所有客戶端
        clients.forEach(client => {
            if (client.readyState === WebSocket.OPEN) {
                try {
                    client.send(JSON.stringify(out));
                } catch (e) {
                    console.error('❌ 廣播失敗:', e);
                }
            }
        });
        
        // 清除header
        delete ws.screenCaptureHeader;
    }
}
```

## 🎮 Unity 接收端實現

### 1. WebRTCScreenReceiver 類

#### 核心初始化
```csharp
void Start()
{
    Debug.Log("🚀 WebRTC 準備就緒");
    
    // ICE 配置
    config = new RTCConfiguration
    {
        iceServers = new[] { 
            new RTCIceServer { urls = new[] { "stun:stun.l.google.com:19302" } },
            new RTCIceServer { urls = new[] { "stun:stun1.l.google.com:19302" } }
        },
        iceCandidatePoolSize = 10
    };
    
    // 初始化 MaterialPropertyBlock
    _mpb = new MaterialPropertyBlock();
    EnsureTargetRendererHasMaterial();
    
    // 訂閱信令事件
    GyroscopeReceiver.OnWebRTCSignaling += HandleSignaling;
    GyroscopeReceiver.OnRawMessage += HandleSignalingText;
}
```

#### Offer 處理流程
```csharp
IEnumerator AcceptOffer(string sdp)
{
    Debug.Log($"🎯 開始處理 Offer SDP: {sdp.Substring(0, Math.Min(30, sdp.Length))}...");
    
    // 清理舊的連接
    if (peerConnection != null)
    {
        peerConnection.Close();
        peerConnection.Dispose();
    }
    
    // 創建新的 PeerConnection
    peerConnection = new RTCPeerConnection(ref config);
    
    // ICE 候選者處理
    peerConnection.OnIceCandidate = candidate =>
    {
        if (candidate == null) return;
        
        var candidateDto = new GyroscopeReceiver.SignalingDTO
        {
            type = "candidate",
            candidate = new GyroscopeReceiver.IceCandidateDTO
            {
                candidate = candidate.Candidate,
                sdpMid = candidate.SdpMid,
                sdpMLineIndex = candidate.SdpMLineIndex ?? 0
            }
        };
        gyroscopeReceiver.SendSignaling(candidateDto);
    };
    
    // ICE 連接狀態改變
    peerConnection.OnIceConnectionChange = state =>
    {
        this.iceConnectionState = state.ToString();
        Debug.Log($"🔌 ICE 狀態: {state}");
        
        if (state == RTCIceConnectionState.Connected || state == RTCIceConnectionState.Completed)
        {
            isConnected = true;
            isWebRTCMode = true;
            Debug.Log("🎉 WebRTC 連接成功！");
            
            // 停用 WebSocket 模式
            var handler = GetComponent<ScreenCaptureHandler>();
            if (handler) handler.enabled = false;
        }
        else if (state == RTCIceConnectionState.Failed || state == RTCIceConnectionState.Disconnected)
        {
            Debug.LogWarning("⚠️ ICE 連接失敗，降級到 WebSocket");
            FallbackToWebSocket();
        }
    };
    
    // 接收遠端軌道
    peerConnection.OnTrack = (RTCTrackEvent e) =>
    {
        if (e.Track is VideoStreamTrack vtrack)
        {
            Debug.Log("📺 收到視頻軌道");
            remoteVideoTrack = vtrack;
            
            // 標記有新紋理，在主線程 Update 中處理
            vtrack.OnVideoReceived += (tex) => {
                Debug.Log($"📺 收到視頻幀: {tex.width}x{tex.height}");
                _pendingTex = tex;
                _hasNewTex = true;
            };
        }
    };
    
    // 設置遠端描述
    var desc = new RTCSessionDescription { type = RTCSdpType.Offer, sdp = sdp };
    var setOp = peerConnection.SetRemoteDescription(ref desc);
    yield return setOp;
    
    // 創建 Answer
    var answerOp = peerConnection.CreateAnswer();
    yield return answerOp;
    var answer = answerOp.Desc;
    
    // 設置本地描述
    var setLocalOp = peerConnection.SetLocalDescription(ref answer);
    yield return setLocalOp;
    
    // 發送 Answer
    var answerDto = new GyroscopeReceiver.SignalingDTO
    {
        type = "answer",
        sdp = answer.sdp
    };
    gyroscopeReceiver.SendSignaling(answerDto);
    
    // 啟動超時檢查
    StartCoroutine(ConnectionTimeoutCheck());
}
```

#### 紋理處理優化
```csharp
void Update()
{
    // WebRTC 內部更新
    WebRTC.Update();
    
    // 主線程紋理更新
    if (_hasNewTex && _pendingTex != null && targetRenderer != null)
    {
        ApplyTextureWithMPB(_pendingTex);
        _hasNewTex = false;
    }
}

private void ApplyTextureWithMPB(Texture tex)
{
    if (targetRenderer == null || tex == null) return;
    
    Material mat = targetRenderer.material;
    
    // 檢查 Shader 是否正確
    if (mat.shader.name != "Unlit/Texture" && 
        mat.shader.name != "Universal Render Pipeline/Unlit")
    {
        Debug.LogWarning($"⚠️ Shader 不正確: {mat.shader.name}，嘗試切換到 Unlit/Texture");
        var unlitShader = Shader.Find("Unlit/Texture");
        if (unlitShader != null)
        {
            mat.shader = unlitShader;
        }
    }
    
    // 方法 1：直接設置 mainTexture（優先）
    mat.mainTexture = tex;
    
    // 方法 2：使用 MaterialPropertyBlock
    targetRenderer.GetPropertyBlock(_mpb);
    _mpb.SetTexture(ID_MainTex, tex);
    _mpb.SetTexture(ID_BaseMap, tex);
    targetRenderer.SetPropertyBlock(_mpb);
    
    Debug.Log($"✅ MaterialPropertyBlock 套用視頻貼圖成功: {tex.width}x{tex.height}");
}
```

### 2. ScreenCaptureHandler 類 (WebSocket 降級)

#### 降級處理邏輯
```csharp
void Start()
{
    // WebSocket 模式作為降級方案
    // 初始禁用，等 WebRTC 失敗時啟用
    this.enabled = false;
    
    // 訂閱事件
    GyroscopeReceiver.OnScreenCaptureReceived += HandleScreenFrame;
    
    // 初始化
    if (targetRenderer == null)
        targetRenderer = GetComponent<Renderer>();
        
    if (screenMaterial == null)
    {
        screenMaterial = new Material(Shader.Find("Standard"));
        targetRenderer.material = screenMaterial;
    }
    
    adaptiveInterval = baseUpdateInterval;
    
    Debug.Log("📺 ScreenCaptureHandler 已初始化（WebSocket 降級模式）");
}
```

#### 幀處理與性能優化
```csharp
void HandleScreenFrame(GyroscopeReceiver.ScreenFrame frame)
{
    // 立即處理模式：直接處理最新幀，丟棄舊的
    if (frameQueue.Count >= maxQueueSize)
    {
        frameQueue.TryDequeue(out _);
    }
    
    frameQueue.Enqueue(frame);
    
    // 立即處理最新幀以減少延遲
    ProcessNextFrame();
    
    Debug.Log($"📺 收到螢幕幀: ClientId={frame.clientId}, Size={frame.size} bytes, 佇列={frameQueue.Count}");
}

void ProcessFrame(GyroscopeReceiver.ScreenFrame frame)
{
    try
    {
        // 重用 Texture2D
        if (screenTexture == null)
        {
            screenTexture = new Texture2D(2, 2, TextureFormat.RGBA32, false);
        }
        
        // 載入圖像（標記為不可讀，減少記憶體使用）
        if (screenTexture.LoadImage(frame.data, true))
        {
            // 應用到材質
            screenMaterial.mainTexture = screenTexture;
            targetRenderer.material = screenMaterial;
            
            frameCount++;
            Debug.Log($"📺 處理螢幕幀 #{frameCount} (ClientId: {frame.clientId}, Size: {frame.size} bytes)");
        }
        else
        {
            Debug.LogError("❌ 無法載入螢幕捕獲數據");
        }
    }
    catch (System.Exception e)
    {
        Debug.LogError($"❌ 處理螢幕幀錯誤: {e.Message}");
    }
}
```

#### 自適應幀率調整
```csharp
void UpdateAdaptiveInterval()
{
    // 計算平均幀時間
    float currentFrameTime = Time.deltaTime;
    frameTimes[frameTimeIndex] = currentFrameTime;
    frameTimeIndex = (frameTimeIndex + 1) % frameTimes.Length;
    
    float avgFrameTime = 0f;
    for (int i = 0; i < frameTimes.Length; i++)
    {
        avgFrameTime += frameTimes[i];
    }
    avgFrameTime /= frameTimes.Length;
    
    // 根據性能調整間隔
    if (avgFrameTime > 0.016f) // 如果幀時間超過16ms
    {
        adaptiveInterval = Mathf.Min(adaptiveInterval * 1.1f, maxUpdateInterval);
    }
    else
    {
        adaptiveInterval = Mathf.Max(adaptiveInterval * 0.95f, baseUpdateInterval);
    }
}
```

### 3. 显示方式对比：Renderer vs RawImage

#### 显示模式枚举定义
```csharp
public enum DisplayMode
{
    Renderer,    // 3D Renderer 模式
    RawImage     // UI RawImage 模式
}
```

#### Renderer 模式实现
```csharp
// 适用于 3D 物体显示
if (displayMode == DisplayMode.Renderer && targetRenderer != null)
{
    Material mat = targetRenderer.material;
    mat.mainTexture = tex;
    
    // 使用 MaterialPropertyBlock 优化
    targetRenderer.GetPropertyBlock(_mpb);
    _mpb.SetTexture(ID_MainTex, tex);
    _mpb.SetTexture(ID_BaseMap, tex);
    targetRenderer.SetPropertyBlock(_mpb);
}
```

#### RawImage 模式实现
```csharp
// 适用于 UI 界面显示
if (displayMode == DisplayMode.RawImage && targetRawImage != null)
{
    targetRawImage.texture = tex;
}
```

#### 显示方式对比表

| 特性 | Renderer 模式 | RawImage 模式 |
|------|---------------|---------------|
| **适用场景** | 3D 物体、世界空间 | UI 界面、屏幕空间 |
| **设置复杂度** | 需要 Material 和 Shader | 直接设置 texture |
| **性能开销** | 较高（Material 处理） | 较低（直接赋值） |
| **Shader 兼容性** | 需要兼容性处理 | 无需处理 |
| **UI 层级管理** | 受 3D 空间限制 | 灵活（Canvas 层级） |
| **调试难度** | 较复杂 | 简单直观 |
| **内存使用** | 需要 Material 对象 | 仅需 Texture |

#### RawImage 配置指南

**Unity Inspector 配置步骤：**

1. **创建 UI Canvas**
   - 在场景中创建 Canvas
   - 设置 Canvas 为 Screen Space - Overlay

2. **添加 RawImage 组件**
   - 在 Canvas 下创建 UI → Raw Image
   - 调整 RawImage 的 RectTransform 大小和位置

3. **配置组件参数**
   - 在 WebRTCScreenReceiver 或 ScreenCaptureHandler 中
   - 设置 Display Mode 为 RawImage
   - 将 RawImage 组件拖拽到 Target RawImage 字段

4. **验证配置**
   - 运行场景，检查视频是否在 RawImage 中显示
   - 查看 Console 日志确认模式切换成功

#### 关键实现代码

**WebRTCScreenReceiver 显示模式支持：**
```csharp
[Header("显示设置")]
public DisplayMode displayMode = DisplayMode.RawImage;
public Renderer targetRenderer;
public RawImage targetRawImage;

// 检查显示目标设置
if (displayMode == DisplayMode.Renderer && targetRenderer == null)
{
    Debug.LogError("❌ Renderer 模式但 targetRenderer 未设置！");
    return;
}
else if (displayMode == DisplayMode.RawImage && targetRawImage == null)
{
    Debug.LogError("❌ RawImage 模式但 targetRawImage 未设置！");
    return;
}
```

**ScreenCaptureHandler 显示模式支持：**
```csharp
[Header("显示设置")]
public DisplayMode displayMode = DisplayMode.RawImage;
public Renderer targetRenderer;
public RawImage targetRawImage;

// 根据显示模式应用纹理
if (displayMode == DisplayMode.RawImage && targetRawImage != null)
{
    targetRawImage.texture = screenTexture;
}
else if (displayMode == DisplayMode.Renderer && targetRenderer != null && screenMaterial != null)
{
    screenMaterial.mainTexture = screenTexture;
    targetRenderer.material = screenMaterial;
}
```

#### RawImage 模式优势

1. **简化配置**: 无需创建和管理 Material 对象
2. **更好性能**: 直接纹理赋值，无额外渲染开销
3. **UI 友好**: 完美适配 Unity UI 系统
4. **易于调试**: 直观的纹理显示，问题排查简单
5. **灵活布局**: 支持 Canvas 的所有布局和动画功能
6. **跨平台兼容**: 无需考虑不同平台的 Shader 兼容性

## 🐛 重要Bug修復記錄

### Bug #1: WebRTC紋理不顯示
**症狀**: WebRTC連接成功但Unity中視頻紋理不顯示  
**原因分析**: 
1. Shader不匹配導致紋理無法正確渲染
2. MaterialPropertyBlock設置不完整
3. 主線程與WebRTC線程的紋理更新衝突

**解決方案**:
```csharp
// 確保使用正確的Shader
Shader shader = Shader.Find("Unlit/Texture");
if (shader == null) shader = Shader.Find("Universal Render Pipeline/Unlit");
mat.shader = shader;

// 主線程紋理更新
vtrack.OnVideoReceived += (tex) => {
    _pendingTex = tex;
    _hasNewTex = true; // 標記有新紋理
};

// 在Update中處理紋理更新
void Update()
{
    if (_hasNewTex && _pendingTex != null)
    {
        ApplyTextureWithMPB(_pendingTex);
        _hasNewTex = false;
    }
}
```

### Bug #2: 信令轉發失敗
**症狀**: WebRTC信令無法正確轉發到Unity端  
**原因分析**: 
1. 伺服器端信令轉發邏輯錯誤
2. JSON序列化格式不匹配
3. 房間配對機制問題

**解決方案**:
```javascript
// 修正信令轉發邏輯
if (['offer', 'answer', 'candidate'].includes(msg.type)) {
    const peers = rooms.get(ws.room) || new Set();
    
    for (const peer of peers) {
        if (peer !== ws && peer.readyState === WebSocket.OPEN) {
            // 確保發送原始 JSON 字符串
            peer.send(JSON.stringify(msg));
        }
    }
}
```

### Bug #3: 記憶體洩漏問題
**症狀**: Unity端記憶體使用量持續增長  
**原因分析**: 
1. Texture2D物件沒有正確重用
2. 事件訂閱沒有正確取消
3. 佇列大小沒有限制

**解決方案**:
```csharp
// Texture2D重用
if (screenTexture == null)
{
    screenTexture = new Texture2D(2, 2, TextureFormat.RGBA32, false);
}

// 佇列大小限制
if (frameQueue.Count >= maxQueueSize)
{
    frameQueue.TryDequeue(out _); // 丟棄舊幀
}

// 正確的事件清理
void OnDestroy()
{
    GyroscopeReceiver.OnScreenCaptureReceived -= HandleScreenFrame;
    CleanupWebRTC();
}
```

## 📊 性能測試結果

### 延遲測試
| 傳輸方式 | 平均延遲 | 最小延遲 | 最大延遲 | 穩定性 |
|---------|---------|---------|---------|--------|
| WebRTC P2P | 150ms | 100ms | 300ms | 85% |
| WebSocket 降級 | 600ms | 400ms | 1000ms | 95% |

### 頻寬使用測試
| 解析度 | WebRTC 位元率 | WebSocket 位元率 | 品質評估 |
|--------|-------------|----------------|----------|
| 1280x720 | 800-1200 kbps | 400-600 kbps | 良好 |
| 1920x1080 | 1500-2500 kbps | 800-1200 kbps | 優秀 |

### 記憶體使用測試
| 組件 | 初始記憶體 | 運行1小時 | 增長率 |
|------|----------|----------|--------|
| Unity WebRTC | 50MB | 65MB | +30% |
| Unity WebSocket | 30MB | 45MB | +50% |
| 瀏覽器端 | 80MB | 120MB | +50% |

## 🔧 配置參數說明

### 前端配置
```javascript
// WebRTC 配置
const rtcConfig = {
    iceServers: [
        { urls: 'stun:stun.l.google.com:19302' },
        { urls: 'stun:stun1.l.google.com:19302' },
        { urls: 'stun:stun2.l.google.com:19302' }
    ],
    iceCandidatePoolSize: 10
};

// 螢幕捕獲配置
const captureConfig = {
    video: {
        width: { ideal: 1280 },
        height: { ideal: 720 },
        frameRate: { ideal: 30, max: 30 }
    },
    audio: false
};
```

### Unity配置
```csharp
[Header("性能設定")]
public int maxQueueSize = 1; // 減少到1，最低延遲
public float baseUpdateInterval = 0.033f; // 30fps base
public float maxUpdateInterval = 0.1f; // 最大10fps
public float connectionTimeout = 18f; // 連接超時時間

[Header("显示设置")]
public DisplayMode displayMode = DisplayMode.RawImage; // 显示模式选择
public Renderer targetRenderer; // 3D Renderer 目标
public RawImage targetRawImage; // UI RawImage 目标
public Material screenMaterial; // 屏幕材质（Renderer模式使用）
```

### 伺服器配置
```javascript
// 房間管理配置
const ROOM_SIZE_LIMIT = 2; // 每個房間最多2個客戶端
const CONNECTION_TIMEOUT = 30000; // 30秒連接超時

// 統計配置
const STATS_INTERVAL = 60000; // 1分鐘統計間隔
const CLEANUP_INTERVAL = 30000; // 30秒清理間隔
```

## 🚀 部署配置

### Railway 部署配置
```toml
# railway.toml
[build]
builder = "NIXPACKS"

[deploy]
startCommand = "npm start"
healthcheckPath = "/health"
restartPolicyType = "ON_FAILURE"
restartPolicyMaxRetries = 3

[env]
NODE_ENV = "production"
PORT = "${{ PORT }}"
```

### 環境變數配置
```bash
# Railway 自動配置
PORT=自動分配
RAILWAY_STATIC_URL=自動生成

# 可選配置
WEBRTC_STUN_SERVERS=stun:stun.l.google.com:19302,stun:stun1.l.google.com:19302
MAX_CONNECTIONS=100
ROOM_TIMEOUT=300000
```

## 📈 監控與調試

### 前端監控指標
```javascript
// WebRTC 統計數據
const stats = {
    bitrate: 0,      // 位元率 (kbps)
    fps: 0,          // 幀率 (fps)
    rtt: 0,          // 往返時間 (ms)
    candidateType: 'unknown' // ICE 候選者類型
};

// 螢幕捕獲統計
const captureStats = {
    frameCount: 0,           // 總幀數
    totalDataSize: 0,        // 總數據大小
    averageFPS: 0,           // 平均幀率
    compressionRatio: 0      // 壓縮比
};
```

### Unity 調試界面
```csharp
void OnGUI()
{
    if (showDebugInfo && Application.isPlaying)
    {
        GUILayout.BeginArea(new Rect(10, 400, 300, 200));
        GUILayout.Label($"WebRTC 模式: {isWebRTCMode}");
        GUILayout.Label($"連接狀態: {isConnected}");
        GUILayout.Label($"視頻紋理: {(_pendingTex != null ? $"{_pendingTex.width}x{_pendingTex.height}" : "無")}");
        if (peerConnection != null)
        {
            GUILayout.Label($"ICE 狀態: {peerConnection.IceConnectionState}");
            GUILayout.Label($"連接狀態: {peerConnection.ConnectionState}");
        }
        GUILayout.EndArea();
    }
}
```

### 伺服器端監控
```javascript
// 健康檢查端點
app.get('/health', (req, res) => {
    res.json({
        status: 'ok',
        uptime: Math.floor((Date.now() - stats.startTime) / 1000),
        connections: {
            active: stats.activeConnections,
            total: stats.totalConnections
        },
        messages: {
            total: stats.totalMessages,
            gyroscope: stats.gyroscopeMessages,
            shake: stats.shakeMessages,
            screenCapture: stats.screenCaptureMessages
        }
    });
});
```

## 🔮 未來優化方向

### 短期優化 (1-2週)
- [ ] **編碼優化**: 實現 H.264 硬體編碼支援
- [ ] **自適應品質**: 根據網路狀況動態調整解析度和幀率
- [ ] **錯誤恢復**: 改進 WebRTC 連接失敗後的自動恢復機制
- [ ] **記憶體優化**: 進一步減少 Unity 端的記憶體使用

### 中期優化 (1個月)
- [ ] **多房間支援**: 支援多個房間同時進行螢幕捕獲
- [ ] **音頻傳輸**: 增加音頻軌道支援
- [ ] **錄製功能**: 添加本地錄製和回放功能
- [ ] **雲端轉碼**: 使用雲端服務進行視頻轉碼優化

### 長期優化 (3個月)
- [ ] **AI 增強**: 使用 AI 進行視頻品質優化和降噪
- [ ] **邊緣計算**: 部署邊緣節點減少延遲
- [ ] **多平台支援**: 擴展到更多平台和設備
- [ ] **企業級功能**: 添加用戶管理、權限控制等功能

## 💡 開發心得與最佳實踐

### 技術學習收穫
1. **WebRTC 複雜性**: 信令處理和 ICE 連接比預期複雜，需要仔細處理各種狀態轉換
2. **性能平衡**: 在品質、延遲、頻寬之間找到最佳平衡點需要大量測試
3. **降級策略**: 完善的降級機制是確保系統穩定性的關鍵
4. **跨平台兼容**: 不同瀏覽器和平台的 WebRTC 支援差異很大

### 最佳實踐總結
1. **模組化設計**: 將 WebRTC 和 WebSocket 功能分離，便於維護和調試
2. **錯誤處理**: 完善的錯誤處理和日誌記錄是調試的關鍵
3. **性能監控**: 即時監控各種性能指標，及時發現問題
4. **用戶體驗**: 自動降級和智能重連機制提升用戶體驗
5. **資源管理**: 正確的資源清理和記憶體管理避免洩漏

### 重要技術決策回顧
1. **選擇 WebRTC P2P 優先**: 雖然實現複雜，但提供了最低延遲
2. **實現雙路徑設計**: 確保系統的可靠性和穩定性
3. **使用房間配對系統**: 簡化了多對端連接管理
4. **優化紋理處理**: 使用 MaterialPropertyBlock 提升性能
5. **實現自適應幀率**: 根據系統性能動態調整更新頻率

---

**最後更新**: 2024年10月18日  
**記錄者**: 開發團隊  
**下次更新**: 完成新功能或重要優化時更新  
**相關文件**: [README.md](README.md), [TROUBLESHOOTING.md](TROUBLESHOOTING.md), [WEBRTC_SETUP.md](WEBRTC_SETUP.md)
